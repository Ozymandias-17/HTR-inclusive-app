{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импорт библиотек, настройка клиента для парсера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements_for_parser.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# установите chromedriver для вашей версии Chrome и укажите путь к приложению chromedriver.exe\n",
    "service = Service(executable_path=r\"YOUR_PATH_TO_chromedriver.exe\")\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_experimental_option('excludeSwitches', ['enable-automation']) \n",
    "options.add_experimental_option('useAutomationExtension', False) \n",
    "options.add_argument(\"--disable-blink-features\") \n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\") \n",
    "options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Парсер для сайта \"Автограф\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pars_autograph:\n",
    "\n",
    "    def __init__(self, login=True):\n",
    "\n",
    "        self.browser = webdriver.Chrome(service=service, options=options)\n",
    "        self.browser.implicitly_wait(4)\n",
    "\n",
    "        self.browser.get('http://literature-archive.ru/ru')\n",
    "\n",
    "        if login==True:\n",
    "\n",
    "            # Эти x_path могут со временем меняться. \n",
    "            # в таком случае необходимо вручную изменить их или выбрать другой метод поиска этих элементов страницы\n",
    "            user_xp = \"/html/body/div[2]/div/div[5]/div/div/div/div[2]/div/section[1]/div/div[2]/form/div/div[1]/input\"\n",
    "            pass_xp = \"/html/body/div[2]/div/div[5]/div/div/div/div[2]/div/section[1]/div/div[2]/form/div/div[2]/input\"\n",
    "            log_xp = \"/html/body/div[2]/div/div[5]/div/div/div/div[2]/div/section[1]/div/div[2]/form/div/div[4]/input\"\n",
    "\n",
    "            # Необходимо зарегистрироваться и вставить сюда свои данные для входа \n",
    "            # это позволит получить более высокое качество изображений\n",
    "            username = 'YOUR_USERNAME'\n",
    "            password = 'YOUR_PASSWORD'\n",
    "\n",
    "            self.browser.find_element(By.XPATH, user_xp).send_keys(username)\n",
    "            time.sleep(random.uniform(0.2, 0.7))    # можно регулировать\n",
    "            self.browser.find_element(By.XPATH, pass_xp).send_keys(password)\n",
    "            time.sleep(random.uniform(0.2, 0.7))    # можно регулировать\n",
    "            self.browser.find_element(By.XPATH, log_xp).click()\n",
    "            time.sleep(random.uniform(0.2, 0.7))    # можно регулировать\n",
    "\n",
    "        soup = BeautifulSoup(self.browser.page_source)\n",
    "\n",
    "        authors_corpus = soup.find(\"div\", {\"class\":\"main_faces\"}).find_all(\"a\", href=True)\n",
    "\n",
    "        self.authors = {}\n",
    "\n",
    "        for author in authors_corpus:\n",
    "            self.authors[author.get('title')] = author.get('href')\n",
    "\n",
    "\n",
    "    def handle_titles(self, title: str, title_counter: dict):\n",
    "        if title in title_counter:\n",
    "            title_counter[title] += 1\n",
    "            return f\"{title}_{title_counter[title]}\"\n",
    "        \n",
    "        else:\n",
    "            title_counter[title] = 1\n",
    "            return title\n",
    "    \n",
    "\n",
    "    def getUniqueItems(self, d: dict):\n",
    "        result = {}\n",
    "        for key,value in d.items():\n",
    "            if value not in result.values():\n",
    "                result[key] = value\n",
    "        return result\n",
    "\n",
    "\n",
    "    def pars_author(self, author_name, parent_directory=\"./data/\"):\n",
    "        \n",
    "        # Path \n",
    "        path = os.path.join(parent_directory, author_name) \n",
    "        \n",
    "        # Create the directory \n",
    "        os.mkdir(path) \n",
    "\n",
    "        if author_name=='Блок Александр Александрович':\n",
    "\n",
    "            url_author = BeautifulSoup(requests.get(self.authors[author_name] + '/en/digital-archive/manuscripts').text)\n",
    "            \n",
    "        else:\n",
    "\n",
    "            url_author = BeautifulSoup(requests.get(self.authors[author_name]).text)\n",
    "\n",
    "        author_archive = url_author.find(\"div\", {\"class\":\"region region-sidebar-first sidebar\"}).find_all(\"a\")\n",
    "\n",
    "        for archive in tqdm(author_archive):\n",
    "            \n",
    "            archive_name = re.sub('\"', '', archive.text).strip()\n",
    "\n",
    "            url_archive = BeautifulSoup(requests.get(self.authors[author_name] + archive.get(\"href\")).text)\n",
    "            \n",
    "            if url_archive.find(\"div\", {\"id\":\"content\"}).find(\"div\", {\"class\":\"view-content\"}):\n",
    "                # Create the directory \n",
    "                os.mkdir(os.path.join(parent_directory, author_name, archive_name)) \n",
    "\n",
    "                url_path = url_archive.find(\"div\", {\"id\":\"content\"}).find(\"div\", {\"class\":\"view-content\"})\\\n",
    "                                    .find_all(\"a\", {\"class\":\"language-link\"})\n",
    "                \n",
    "                material_urls = [(self.authors[author_name] + m_url.get(\"href\")) for m_url in url_path]\n",
    "\n",
    "                title_path = url_archive.find(\"div\", {\"id\":\"content\"}).find(\"div\", {\"class\":\"view-content\"})\\\n",
    "                                        .find_all(\"a\", {\"rel\":\"tag\"})\n",
    "                    \n",
    "                title_counter = {}\n",
    "\n",
    "                material_titles = [self.handle_titles(m_title.get(\"title\").strip(), title_counter) for m_title in title_path]\n",
    "\n",
    "                materials_raw = dict(zip(material_titles, material_urls))\n",
    "\n",
    "                materials = self.getUniqueItems(materials_raw)\n",
    "\n",
    "                title_counter.clear()\n",
    "\n",
    "                for title, material in materials.items():\n",
    "\n",
    "                    title_formated = re.sub(r'[\\\\/*?:\"<>|]', '', title)[:85].strip()\n",
    "\n",
    "                    unique_title = self.handle_titles(title_formated, title_counter)\n",
    "\n",
    "                    os.mkdir(os.path.join(parent_directory, author_name, archive_name, unique_title))\n",
    "\n",
    "                    self.browser.get(materials[title])\n",
    "                    time.sleep(random.uniform(0.9, 4.1))   # можно регулировать\n",
    "\n",
    "                    global content\n",
    "\n",
    "                    content = BeautifulSoup(self.browser.page_source)\n",
    "\n",
    "                    meta_titles = [mark.text for mark in content.find(\"div\", {\"id\":\"block-system-main\"}).find_all(\"h2\")]\n",
    "\n",
    "                    meta_titles.append(\"Описание: \")\n",
    "\n",
    "                    meta_inf = [inf.text for inf in content.find(\"div\", {\"id\":\"block-system-main\"}).find_all(\"div\", {\"class\":\"field-item even\"})[1:]]\n",
    "\n",
    "                    self.meta_data = pd.DataFrame([dict(zip(meta_titles, meta_inf))]).T\n",
    "\n",
    "                    with pd.ExcelWriter(f\"{path}/{archive_name}/{unique_title}/meta_data.xlsx\") as writer:\n",
    "                        self.meta_data.to_excel(writer)\n",
    "\n",
    "                    self.scans = content.find(\"div\", {\"id\":\"block-system-main\"}).find_all(\"a\")\n",
    "\n",
    "                    counter = 1\n",
    "\n",
    "                    for scan in self.scans:\n",
    "\n",
    "                        try:\n",
    "                            image_url = scan.get(\"href\")\n",
    "                        except:\n",
    "                            continue\n",
    "\n",
    "                        if len(image_url) > 50:\n",
    "\n",
    "                            try:\n",
    "\n",
    "                                urllib.request.urlretrieve(image_url, f\"{path}/{archive_name}/{unique_title}/{counter}.png\")\n",
    "                                counter += 1\n",
    "\n",
    "                            except:\n",
    "                                continue\n",
    "                        \n",
    "                        else:\n",
    "                            continue\n",
    "            else:\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация класса\n",
    "autoghraph = pars_autograph(login=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотреть авторов\n",
    "autoghraph.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_athors = ['Пастернак Борис Леонидович', 'Булгаков Михаил Афанасьевич', 'Блок Александр Александрович']  # пример\n",
    "\n",
    "for ath in target_athors:\n",
    "    # Можно задать другой parent_directory, но рекомендуется хранить данные в каталоге с именем 'Authors_Manusripts'\n",
    "    autoghraph.pars_author(author_name=ath, parent_directory=\"./data/Authors_Manusripts/\")\n",
    "    time.sleep(random.uniform(55, 90))  # можно регулировать"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
